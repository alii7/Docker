docker run hello-world          # to create container(an instance of an image)
docker run -it centos /bin/bash      # -it(interactive mode), /bin/bash( run the bash shell once CentOS is up and running)
docker images                # to see the list of Docker images on the system
docker rmi ImageID           # to remove Docker images on the system
docker images -q        # to return only the Image ID’s of the images
docker inspect image_name    # to see the details of an image or container  (image_name = Repository)
docker ps                    # to list all of the containers on the machine (currently running)
docker ps -a                 # to list all of the containers on the system
docker history ImageID       # to see all the commands that were run with an image via a container
docker history image_name    # to see all the commands that were run with an image via a container
docker top ContainerID       # to see the top processes within a container
docker stop ContainerID      # to stop a running container
docker rm ContainerID        # to delete a container
docker stats ContainerID     # to provide the statistics of a running container (CPU and memory utilization of the Container)
docker attach ContainerID    # to attach to a running container

Once you have attached to the Docker container, you can run the above command to see the process utilization in that Docker container

docker pause ContainerID     # to pause the processes in a running container
docker unpause ContainerID   # to unpause the processes in a running container
docker kill ContainerID      # to kill the processes in a running container


service docker stop           # to stop the Docker daemon process
service docker start          # to start the Docker daemon process


Ctrl+P+Q     # to exit out of the container. It ensures that the container still exists even after we exit from the container.
If we had to exit out of the container directly, then the container itself would be destroyed.

There is an easier way to attach to containers and exit them cleanly without the need of destroying them: NSENTER
1) docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter     # install nsenter image
2) docker inspect image_ID | grep Pid                             # to get the Process ID via the Docker inspect command and filtering it via the Pid


nsenter –m –u –n –p –i –t containerID command         #  NSENTER SYNTAX
sudo nsenter –m –u –n –p –i –t 2978 /bin/bash         #  NSENTER EXAMPLE

-u is used to mention the Uts namespace
-m is used to mention the mount namespace
-n is used to mention the network namespace
-p is used to mention the process namespace
-i s to make the container run in interactive mode.
-t is used to connect the I/O streams of the container to the host OS.
containerID − This is the ID of the container.
command − This is the command to run within the container.

CONSEQUENCE OF NSENTER:
The prompt changes to the bash shell directly when we issue the nsenter command.
We then issue the exit command. But you would notice that when we run the nsenter command, the container is still up and running.(NOT DESTROYED)

FROM ubuntu                                 #
MAINTAINER demousr@gmail.com                #
                                            #
RUN apt-get update                          #   DOCKERFILE EXAMPLE (Dockerfile)
RUN apt-get install –y nginx                #
CMD [“echo”,”Image created”]                #

FROM            : which base image you want to base your image (we are creating an image from the ubuntu image)
MAINTAINER      : the person who is going to maintain this image  (just mention the email ID)
RUN             : to run instructions against the image
CMD             : to display a message to the user


docker build  -t ImageName:TagName dir              # to build your own Docker images
dir : The directory where the Docker File is present

docker tag imageID Repositoryname                     # to tag an image to the relevant repository
docker tag ab0c1d3744dd demousr/demorep:1.0           # TAG EXAMPLE
docker push Repositoryname                            # to push images to the Docker Hub
docker push demousr/demorep:1.0                       # PUSH EXAMPLE



In Docker, the containers themselves can have applications running on ports. 
When you run a container, if you want to access the application in the container via a port number, you need to map the port number of the container to the port number of the Docker host.

To understand what ports are exposed by the container, you should use the Docker inspect command to inspect the image.

docker inspect Container/Image          # to return low-level information on the container or image  (in JSON format)
docker run -p 8080:8080 -p 50000:50000 jenkins     # to run Jenkins and map the ports

8080 ==>  the Docker host port
50000 ==>  the Docker container port

When you open the browser and navigate to the Docker host on port 8080, you will see Jenkins up and running.

-----------------------------------------------------------------------------------------------------------------------------------------

EXPOSE 80 :  to expose port 80 of Apache in the container to the Docker host
CMD [“apache2ctl”, “-D”, “FOREGROUND”]   :   to run apache2 in the background

CMD command param1          # to execute a command at runtime when the container is executed
CMD [“echo” , “hello world”]      #  CMD EXAMPLE

ENTRYPOINT command param1     # to execute commands at runtime for the container. But, this command is more flexible.

ENV key value                 # to set environment variables in the container
ENV var1=Tutorial var2=point  # ENVIRONMENT EXAMPLE

WORKDIR dirname               # to set the working directory of the container
WORKDIR /newtemp              # WORKDIR EXAMPLE


Container Linking allows multiple containers to link with each other. It is a better option than exposing ports.
docker run --name=jenkinsa -d jenkins     # to specify a name to the container by using the –-name option (source container)
docker run --name=reca --link=jenkinsa:alias-src -it ubuntu:latest /bin/bash     # to launch the destination container, but this time, we will link it with our source container
docker attach reca     # to attach to the receiving container
Then run the env command. You will notice new variables for linking with the source container.(ALIAS_SRC)


Docker has multiple storage drivers that allow one to work with the underlying storage devices :
overlay or overlay2, aufs, brtfs, devicemanager, vfs,zfs

AUFS :
This is a stable driver; can be used for production-ready applications.
It has good memory usage and is good for ensuring a smooth Docker experience for containers.
There is a high-write activity associated with this driver which should be considered.
It’s good for systems which are of Platform as a service type work.
Device Manager :
This is a stable driver; ensures a smooth Docker experience.
This driver is good for testing applications in the lab.
This driver is in line with the main Linux kernel functionality.
Btrfs :
This driver is in line with the main Linux kernel functionality.
There is a high-write activity associated with this driver which should be considered.
This driver is good for instances where you maintain multiple build pools.
OverlayFS :
This is a stable driver and it is in line with the main Linux kernel functionality.
It has a good memory usage.
This driver is good for testing applications in the lab.
ZFS :
This is a stable driver and it is good for testing applications in the lab.
It’s good for systems which are of Platform-as-a-Service type work.

docker info           # to see the storage driver being used


Data volume is a separate volume that can be shared across containers.
They are initialized when the container is created.
They can be shared and also reused amongst many containers.
Any changes to the volume itself can be made directly.
They exist even after the container is deleted.

sudo docker inspect Jenkins > tmp.txt             # When you view the text file using the more command, you will see an entry as JENKINS_HOME=/var/Jenkins_home.
This is the mapping that is done within the container via the Jenkins image.
docker run –d –v /home/demo:/var/jenkins_home –p 8080:8080 –p 50000:50000 jenkins    # to map the volume in the container to a local volume
You need to specify the –v option when launching the container.

sudo docker run –d --volume-driver=flocker –v /home/demo:/var/jenkins_home –p 8080:8080 –p 50000:50000 jenkins    # to change to the storage driver used for a container
The –volume-driver option is used to specify another storage driver for the container.
docker inspect 9bffb1bfebee > temp.txt          # to inspect volume driver
If you browse through the text file and go to the line which says "VolumeDriver", you will see that the driver name has been changed.

docker volume create –-name=volumename –-opt options          # to create volume
sudo docker volume create –-name = demo –opt o = size = 100m            # VOLUME CREATE EXAMPLE
docker volume ls                    # to list all the docker volumes on a docker host



Docker takes care of the networking aspects so that the containers can communicate with other containers and also with the Docker Host.
ifconfig                  # to see the Docker Ethernet adapter
docker network ls         # to list all the networks associated with Docker on the host
docker network inspect network_name     # to output all the details about the network
docker network inspect bridge           # EXAMPLE

One can create a network in Docker before launching containers.

docker network create –-driver drivername name      # to create network
docker network create –-driver bridge new_nw        # EXAMPLE
docker run –it –network=new_nw ubuntu:latest /bin/bash     # to attach the new network when launching the container


sudo docker run –it –rm –name = HelloWorld –v “$PWD”:/usr/src/app –w /usr/src/app node node HelloWorld.js  #
The –rm option is used to remove the container after it is run.
The –w option is used to specify the working directory used by Node.js.
The first node option is used to specify to run the node image.
The second node option is used to mention to run the node command in the node container.


This name (container name) will be different since the name of the containers keep on changing when you spin up a container.

Docker has logging mechanisms to debug issues.
There is logging at the daemon level and at the container level.

Daemon Logging :
Debug   : It details all the possible information handled by the daemon process.
Info    : It details all the errors + Information handled by the daemon process.
Errors  : It details all the errors handled by the daemon process.
Fatal   : It only details all the fatal errors handled by the daemon process.

How To Enable Logging :

service docker stop           # to stop the docker daemon process
dockerd –l debug &            # to start the docker daemon process by appending the –l parameter to specify the logging option
dockerd is executable for the docker daemon process
The –l option is used to specify the logging level.
& is used to come back to the command prompt after the logging has been enabled
Now, if you execute any Docker command such as docker images, the Debug information will also be sent to the console.

Container Logging :

docker logs containerID               # to see the logs of the container
docker logs 6bfb1271fcdd              # DOCKER LOG EXAMPLE
you can see that the commands executed in the container are shown in the logs (via ls command while in the container)


Docker Compose is used to run multiple containers as a single service.
curl -L "https://github.com/docker/compose/releases/download/1.10.0-rc2/dockercompose -$(uname -s) -$(uname -m)" -o /home/demo/docker-compose # to download the necessary files from github
chmod +x /home/demo/docker-compose          # to provide execute privileges to the downloaded Docker Compose file
docker-compose version                      # to see the compose version
./docker-compose -version                   # EXAMPLE
All Docker Compose files are YAML files.

docker-compose.yml :                          #
version: '2'                                  #
services:                                     #
    databases:                                #
      image: mysql                            #
      ports:                                  #
      - "3306:3306"                           #
      environment:                            #    DOCKER-COMPOSE FILE EXAMPLE
      - MYSQL_ROOT_PASSWORD=password          #
      - MYSQL_USER=user                       #
      - MYSQL_PASSWORD=password               #
      - MYSQL_DATABASE=demodb                 #
    web:                                      #
      image: nginx                            #
      
The database and web keyword are used to define two separate services. One will be running our mysql database and the other will be our nginx web server.
The image keyword is used to specify the image from dockerhub for our mysql and nginx containers.
For the database, we are using the ports keyword to mention the ports that need to be exposed for mysql.
And then, we also specify the environment variables for mysql which are required to run mysql.

./docker-compose up                           # to  run our Docker Compose file


docker system df                # to check the disk usage of docker
docker system prune             # to remove unused data
docker images -f "dangling=true"      # to show only dangling images (dangling images = associated with running containers)

Images are a stack of layers.   # see with docker inspect

docker-cpmpose config     # to check whether is correct file or not






















